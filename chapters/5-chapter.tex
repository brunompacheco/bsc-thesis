% ----------------------------------------------------------
\chapter{Deep Equilibrium Models}\label{ch:deq}
% ----------------------------------------------------------

This chapter is dedicated to lay out the foundations of the model architecture that is the central investigation point of this work.
\gls{DEQ}s have been proposed by \textcite{Bai2019} and \textcite{Ghaoui2019}, the latter naming them \emph{implicit models}.
In this chapter, we follow the notation of the former.

Furthermore, one of the greatest challenges in working with \gls{DEQ}s is that, by their implicit nature, they do not fit perfectly well with current deep learning tools.
Therefore, to better understand the nuances and challenges that this family of models present during the experiments, a good share of attention is dedicated to the specificities of performing back propagation with \gls{DEQ}s.

\section{Introduction and Definition}

In Chapter \ref{ch:deep-learning}, the intuition behind a deep learning model was introduced, that is, to model complex features through the composition of simple-yet-non-linear parametrized functions.
Besides the network defined in \ref{sec:neural-nets} (which is the base for \gls{PINN}s, as shown in chapter \ref{ch:pinn}), many other deep learning model architectures have been proposed over the years.
    Some of the architectures with the most surprising results involve composing the models with the same function applied multiple times, i.e., following the notation of chapter \ref{ch:deep-learning}, instead of defining the model as $f_{\gls{param}}=f_{\gls{param}}^{[L]}\circ \cdots \circ f_{\gls{param}}^{[1]}$, these architectures suggest a model similar to $f_{\gls{param}}=f_{\gls{param}}^{[1]}\circ \cdots \circ f_{\gls{param}}^{[1]}$.
Inspired by this, \textcite{Bai2019} takes a step further, defining the model with a (possibly) infinite stack of the same function, which was named \gls{DEQ}.

Let us recall the definition of a deep learning model as proposed in equation \eqref{eq:dl-model}, but imagine it has an infinite number of layers (infinite depth).
Of course, if each $f^{[i]}$ is a different function (with different parameters), then this would be impossible to fit in memory.
Therefore, let us assume that $f_{\gls{param}}^{[i]}=f_{\gls{param}}^{[EQ]},\forall i$, i.e.,
\begin{equation*}
\begin{split}
    z^{[0]} &= x \\
    z^{[i]} &= f_{\gls{param}}^{[EQ]}(z^{[i-1]}), \forall i\ge 1
,\end{split}
\end{equation*}
in which the output would be $z^{\star} = z^{[\infty]}$.
If this iterative process converges, that is, if there is a number $N$ such that $\forall i\ge N,\,z^{[i]}\approx z^{[i+1]}$, then the output $z^{\star}\approx z^{[N]}$ is well-defined, and it is true that  \[
    z^{\star} = f_{\gls{param}}\left( z^{\star} \right) 
.\] 
One can say that $z^{\star}$ is an \emph{equilibrium point} of $f_{\gls{param}}^{[EQ]}$.
Therefore, the output of a well-behaved (i.e., one that respects the restrictions above presented) infinite-depth deep learning model can be computed by finding its equilibrium point.

The model proposed by \textcite{Bai2019} has a slight change in how it handles the input, feeding the input vector at each layer of the model. More precisely, we can say that a \gls{DEQ} of the form
\begin{align*}
    \bm{f}_{\gls{param}}: \R^{n} &\longrightarrow \R^{m} \\
    \bm{x} &\longmapsto \bm{f}_{\gls{param}}(\bm{x}) = \bm{z}^{\star}
\end{align*}
defines its output as the equilibrium point of a function $\bm{f}_{\gls{param}}^{[EQ]}:\R^{n+m}\to \R^{m}$
\begin{equation}\label{eq:z-star}
    \bm{z}^{\star} = \bm{f}_{\gls{param}}^{[EQ]}\left( \bm{x},\bm{z} \right) 
.\end{equation}

\section{Forward}

- naÃ¯ve approach: iterate the model until an equilibrium is found
- better approach, use any black-box root-finding method
- brief explanation on how root finding methods work? or maybe just introduce quasi-newton methods? or maybe nothing at all?

\subsection{Jacobian Regularization}

- show that a small jacobian => faster convergence

\section{Backward}

\section{Implementation}

