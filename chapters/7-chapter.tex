% ----------------------------------------------------------
\chapter{Conclusion}\label{ch:conclusion}
% ----------------------------------------------------------

An in-depth study was carried out with two novel approaches in the big area of deep learning: \gls{PINN} and {DEQ}.
Both provide a deeper connection between deep learning and other areas of knowledge, such as differential equations, optimization, and numerical analysis.
\gls{PINN}s provide an efficient approach to train deep learning models on problems involving physical phenomena.
\gls{DEQ}s are a promising new architecture that can provide a larger representational power with a small number of parameters.
This work proposed an application that combines both: using \gls{PIDEQ}s to solve \gls{IVP}s of \gls{ODE}s.
For this, we successfully studied, implemented and tested several \gls{PIDEQ} models.

To the best of our knowledge, this is the first study on physics regularization (or any gradient regularization) for \gls{DEQ}s.
In fact, we have not found any published result reporting higher-order derivatives of these models, as \textcite{Bai2019} only proposed an analytical solution for the first derivative.
The requirement for higher-order derivatives imposes limitations to the model, namely the use of a differentiable solver to compute the first derivative.

To validate the implementation of the model, we trained \gls{PIDEQ}s to solve \gls{IVP}s of the Van der Pol oscillator, a well-known, \gls{ODE}-governed system.
The experimental results showed that differentiating through the backward-pass solver (used to compute the first derivative) did not have a big impact in the speed of training.
Computing the equilibrium (forward pass) and the Jacobian regularization are the most costly operations in comparison to \gls{PINN}s, at least for small \glspl{PIDEQ}.
We hypothesize that larger models and more complex problems may result in harder-to-compute derivatives, as it may be harder to find equilibria efficiently.
This would change not only the forward pass but also the Jacobian used by the backward pass, therefore, requiring more iterations of the differentiable solver (simple iteration method) or even a more robust solver.

Comparing \gls{PIDEQ} results with \gls{PINN} models showed that the former has a larger approximation error and slower training.
Still, both presented very small errors in the proposed problems, to the point of being almost indistinguishable visually.
These results indicate that the inner structure of \glspl{DEQ} do not provide significant advantage for learning to solve the problem at hand.

% the task is about extracting complex functions out of low-dimensional data, not usual, given the current trends of extracting simpler functions out of high-dimensional data

\section{Outlook}

Given that \gls{DEQ}s approximate infinite-depth models, it is reasonable to imagine that they would be more effective in problems that benefit from deeper models, whereas in the problem considered in this work, even a shallow deep feedforward network was able to properly approximate the target function.
Therefore, it is natural that a next step is to apply the proposed model to more complex problems.
The four-tanks system \cite{johansson_quadruple-tank_2000,gatzke_model_2000}, which was better solved with deeper networks in the approach of \textcite{Antonelo2021}, could benefit from \glspl{PIDEQ}.
Also, the proposed model could easily be generalized to partial differential equations, and then compared to the original \gls{PINN} of \textcite{Raissi2019}.

A variation of the \gls{IVP} as discussed here is to train a model that can provide approximate solutions for a set of initial conditions, as discussed in \textcite{Antonelo2021,Arnold2021}.
This enables the efficient use of \glspl{PINN} for control problems.
Being able to train models for this problem with fewer parameters (such as \glspl{PIDEQ}) can be very useful for increasing explainability and, thus, robustness for the controller.

Lastly, another way to make \glspl{PIDEQ} more competitive is to improve their efficiency.
In principle, the second (and any higher-order) derivative of \glspl{DEQ} can be implicitly computed, without the necessity of differentiating the solver, by using the implicit function theorem.
This has the potential to significantly save training time, mainly for larger \glspl{DEQ}, by allowing the use of non-differentiable solvers for computing the first derivative of the output.

